1. Modelul bag-of-words
â” este o metodÄƒ de reprezentare a datelor de tip text, bazatÄƒ pe frecvenÈ›a
de apariÈ›ie a cuvintelor Ã®n cadrul documentelor
â” algoritmul este alcÄƒtuit din 2 paÈ™i:
1. definirea unui vocabular prin atribuirea unui id unic fiecÄƒrui
cuvÃ¢nt regÄƒsit Ã®n setul de date (setul de antrenare)
2. reprezentarea fiecÄƒrui document ca un vector de dimensiune
egalÄƒ cu lungimea vocabularului, definit astfel:
ğ‘“ğ‘’ğ‘ğ‘¡ğ‘¢ğ‘Ÿğ‘’ğ‘ [ğ‘¤ğ‘œğ‘Ÿğ‘‘_ğ‘–ğ‘‘ğ‘¥] = ğ‘›ğ‘¢ğ‘šÄƒğ‘Ÿğ‘¢ğ‘™ ğ‘‘ğ‘’ ğ‘ğ‘ğ‘ğ‘Ÿğ‘–È›ğ‘–ğ‘– ğ‘ğ‘™ ğ‘ğ‘¢ğ‘£Ã¢ğ‘›ğ‘¡ğ‘¢ğ‘™ğ‘¢ğ‘– ğ‘ğ‘¢ ğ‘–ğ‘‘ âˆ’ ğ‘¢ğ‘™ ğ‘¤ğ‘œğ‘Ÿğ‘‘_ğ‘–ğ‘‘ğ‘¥

Functii folosite:
â” def normalize_data(train_data, test_data, type = None):   primeste datele de intrare si iesire si intoarce aceste date normalizate in functie de tip: STANDARD, min_max, l1,l2 l2
â”def build_vocabulary(self,data): primeste ca parametru o lista de mesaje si construieste vocabularul be baza acesteia
â”def get_features(self,data): primeste ca parametru o lista de mesaje si returneaza o matrice definita astfel: ğ’‡ğ’†ğ’‚ğ’•ğ’–ğ’“ğ’†ğ’”(ğ’”ğ’‚ğ’ğ’‘ğ’ğ’†_ğ’Šğ’…ğ’™,ğ’˜ğ’ğ’“ğ’…_ğ’Šğ’…ğ’™) = ğ’ğ’–ğ’ğ’‚ğ’“ğ’–ğ’ ğ’…ğ’† ğ’‚ğ’‘ğ’‚ğ’“ğ’Šğ’•ğ’Šğ’Š ğ’‚ğ’
 ğ’„ğ’–ğ’—ğ’‚ğ’ğ’•ğ’–ğ’ğ’–ğ’Š ğ’„ğ’– ğ’Šğ’…âˆ’ ğ’–ğ’ ğ’˜ğ’ğ’“ğ’…_ğ’Šğ’…ğ’™ ğ’Šğ’ ğ’…ğ’ğ’„ğ’–ğ’ğ’†ğ’ğ’•ğ’–ğ’ ğ’”ğ’‚ğ’ğ’‘ğ’ğ’†_ğ’Šğ’…ğ’™
â”def coefficients(classifier, feature_names, top_features=10): AfiÈ™eaza cele mai negative (spam) 10 cuvinte È™i cele mai pozitive (non-spam) 10
cuvinte.

â”Build the vocabulary:
    BOW = BagOfWords()
    BOW.build_vocabulary(training_sentences)

â”Transforming text into numerical features:
    train_feat = BOW.get_features(training_sentences)
    test_feat = BOW.get_features(test_sentences)
    
â”Normalizing numerical features:
    norm_data = normalize_data(train_feat,test_feat,'l2')
    
â”SVM model training:
    obj = svm.SVC(1,kernel = 'linear')
    obj.fit(norm_data[0],training_labels)
    
â”Predictions:
    predictions = obj.predict(norm_data[1])
 
â”Accuracy:
    accur = accuracy_score(test_labels,predictions)

â”F1-score:
    f1_scor = f1_score(test_labels,predictions,average =None)
    
â”Printing the most important features (negative and positive):
    coefficients(obj, norm_data[1])
